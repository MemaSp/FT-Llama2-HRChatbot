{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.339712918660287,
  "eval_steps": 500,
  "global_step": 70,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02,
      "grad_norm": 2.4957993030548096,
      "learning_rate": 0.0001,
      "loss": 2.6676,
      "step": 1
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.9952218532562256,
      "learning_rate": 0.0002,
      "loss": 3.0545,
      "step": 2
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.536421775817871,
      "learning_rate": 0.00019705882352941177,
      "loss": 2.5425,
      "step": 3
    },
    {
      "epoch": 0.08,
      "grad_norm": 3.173297166824341,
      "learning_rate": 0.00019411764705882354,
      "loss": 1.7635,
      "step": 4
    },
    {
      "epoch": 0.1,
      "grad_norm": 4.114598274230957,
      "learning_rate": 0.0001911764705882353,
      "loss": 1.2819,
      "step": 5
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.202885866165161,
      "learning_rate": 0.00018823529411764707,
      "loss": 1.0294,
      "step": 6
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.120414972305298,
      "learning_rate": 0.00018529411764705883,
      "loss": 0.828,
      "step": 7
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.3451309204101562,
      "learning_rate": 0.0001823529411764706,
      "loss": 0.6,
      "step": 8
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.6343801021575928,
      "learning_rate": 0.00017941176470588236,
      "loss": 0.4959,
      "step": 9
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.037243366241455,
      "learning_rate": 0.00017647058823529413,
      "loss": 0.7113,
      "step": 10
    },
    {
      "epoch": 0.21,
      "grad_norm": 3.1079423427581787,
      "learning_rate": 0.0001735294117647059,
      "loss": 0.6281,
      "step": 11
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.7407772541046143,
      "learning_rate": 0.00017058823529411766,
      "loss": 0.6459,
      "step": 12
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.270189642906189,
      "learning_rate": 0.00016764705882352942,
      "loss": 0.4238,
      "step": 13
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.4970256090164185,
      "learning_rate": 0.0001647058823529412,
      "loss": 0.4348,
      "step": 14
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.194128394126892,
      "learning_rate": 0.00016176470588235295,
      "loss": 0.3265,
      "step": 15
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.351372241973877,
      "learning_rate": 0.0001588235294117647,
      "loss": 0.4533,
      "step": 16
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.7047759890556335,
      "learning_rate": 0.00015588235294117648,
      "loss": 0.3161,
      "step": 17
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.7986274361610413,
      "learning_rate": 0.00015294117647058822,
      "loss": 0.28,
      "step": 18
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.8883679509162903,
      "learning_rate": 0.00015000000000000001,
      "loss": 0.3425,
      "step": 19
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.9332913756370544,
      "learning_rate": 0.00014705882352941178,
      "loss": 0.4066,
      "step": 20
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.0793776512145996,
      "learning_rate": 0.00014411764705882354,
      "loss": 0.3782,
      "step": 21
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.0672800540924072,
      "learning_rate": 0.0001411764705882353,
      "loss": 0.4529,
      "step": 22
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.6662229895591736,
      "learning_rate": 0.00013823529411764707,
      "loss": 0.3125,
      "step": 23
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.6140764951705933,
      "learning_rate": 0.00013529411764705884,
      "loss": 0.2993,
      "step": 24
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.52597576379776,
      "learning_rate": 0.0001323529411764706,
      "loss": 0.2509,
      "step": 25
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.5652410387992859,
      "learning_rate": 0.00012941176470588237,
      "loss": 0.2642,
      "step": 26
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.6085184812545776,
      "learning_rate": 0.0001264705882352941,
      "loss": 0.2772,
      "step": 27
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.5863231420516968,
      "learning_rate": 0.0001235294117647059,
      "loss": 0.3605,
      "step": 28
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.6208836436271667,
      "learning_rate": 0.00012058823529411765,
      "loss": 0.3182,
      "step": 29
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.7165494561195374,
      "learning_rate": 0.00011764705882352942,
      "loss": 0.2712,
      "step": 30
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.6422979831695557,
      "learning_rate": 0.00011470588235294118,
      "loss": 0.3198,
      "step": 31
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.7642675042152405,
      "learning_rate": 0.00011176470588235294,
      "loss": 0.3783,
      "step": 32
    },
    {
      "epoch": 0.63,
      "grad_norm": Infinity,
      "learning_rate": 0.00011176470588235294,
      "loss": 0.3391,
      "step": 33
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.6309452652931213,
      "learning_rate": 0.0001088235294117647,
      "loss": 0.2459,
      "step": 34
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.48086604475975037,
      "learning_rate": 0.00010588235294117647,
      "loss": 0.238,
      "step": 35
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.42613714933395386,
      "learning_rate": 0.00010294117647058823,
      "loss": 0.252,
      "step": 36
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.237391710281372,
      "learning_rate": 0.0001,
      "loss": 0.2853,
      "step": 37
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.439602792263031,
      "learning_rate": 9.705882352941177e-05,
      "loss": 0.2753,
      "step": 38
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.5210766196250916,
      "learning_rate": 9.411764705882353e-05,
      "loss": 0.2322,
      "step": 39
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.8292787075042725,
      "learning_rate": 9.11764705882353e-05,
      "loss": 0.3703,
      "step": 40
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.7245997786521912,
      "learning_rate": 8.823529411764706e-05,
      "loss": 0.4008,
      "step": 41
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.6076574325561523,
      "learning_rate": 8.529411764705883e-05,
      "loss": 0.3599,
      "step": 42
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.48349621891975403,
      "learning_rate": 8.23529411764706e-05,
      "loss": 0.221,
      "step": 43
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.3822813332080841,
      "learning_rate": 7.941176470588235e-05,
      "loss": 0.1896,
      "step": 44
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.4484825134277344,
      "learning_rate": 7.647058823529411e-05,
      "loss": 0.2343,
      "step": 45
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.33339548110961914,
      "learning_rate": 7.352941176470589e-05,
      "loss": 0.1601,
      "step": 46
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.6079674363136292,
      "learning_rate": 7.058823529411765e-05,
      "loss": 0.2619,
      "step": 47
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.36556097865104675,
      "learning_rate": 6.764705882352942e-05,
      "loss": 0.2434,
      "step": 48
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.42320871353149414,
      "learning_rate": 6.470588235294118e-05,
      "loss": 0.2555,
      "step": 49
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.4316229820251465,
      "learning_rate": 6.176470588235295e-05,
      "loss": 0.2416,
      "step": 50
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.454235315322876,
      "learning_rate": 5.882352941176471e-05,
      "loss": 0.2718,
      "step": 51
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.5708449482917786,
      "learning_rate": 5.588235294117647e-05,
      "loss": 0.2986,
      "step": 52
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.3811144530773163,
      "learning_rate": 5.294117647058824e-05,
      "loss": 0.2343,
      "step": 53
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.32528433203697205,
      "learning_rate": 5e-05,
      "loss": 0.1894,
      "step": 54
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.38618797063827515,
      "learning_rate": 4.705882352941177e-05,
      "loss": 0.2652,
      "step": 55
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.46875688433647156,
      "learning_rate": 4.411764705882353e-05,
      "loss": 0.2627,
      "step": 56
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.41020265221595764,
      "learning_rate": 4.11764705882353e-05,
      "loss": 0.2169,
      "step": 57
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.4080592095851898,
      "learning_rate": 3.8235294117647055e-05,
      "loss": 0.1916,
      "step": 58
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.5017005801200867,
      "learning_rate": 3.529411764705883e-05,
      "loss": 0.2431,
      "step": 59
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.3549194633960724,
      "learning_rate": 3.235294117647059e-05,
      "loss": 0.1815,
      "step": 60
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.3531527817249298,
      "learning_rate": 2.9411764705882354e-05,
      "loss": 0.2237,
      "step": 61
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.3830481469631195,
      "learning_rate": 2.647058823529412e-05,
      "loss": 0.2373,
      "step": 62
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.46478790044784546,
      "learning_rate": 2.3529411764705884e-05,
      "loss": 0.3082,
      "step": 63
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.36214378476142883,
      "learning_rate": 2.058823529411765e-05,
      "loss": 0.1573,
      "step": 64
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.36263036727905273,
      "learning_rate": 1.7647058823529414e-05,
      "loss": 0.176,
      "step": 65
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.44543153047561646,
      "learning_rate": 1.4705882352941177e-05,
      "loss": 0.2774,
      "step": 66
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.5187475681304932,
      "learning_rate": 1.1764705882352942e-05,
      "loss": 0.2718,
      "step": 67
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.4865124225616455,
      "learning_rate": 8.823529411764707e-06,
      "loss": 0.2804,
      "step": 68
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.6806530356407166,
      "learning_rate": 5.882352941176471e-06,
      "loss": 0.3365,
      "step": 69
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.39571142196655273,
      "learning_rate": 2.9411764705882355e-06,
      "loss": 0.1642,
      "step": 70
    },
    {
      "epoch": 1.34,
      "step": 70,
      "total_flos": 1317445759598592.0,
      "train_loss": 0.46727486635957444,
      "train_runtime": 507.7691,
      "train_samples_per_second": 0.551,
      "train_steps_per_second": 0.138
    }
  ],
  "logging_steps": 1,
  "max_steps": 70,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "total_flos": 1317445759598592.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
