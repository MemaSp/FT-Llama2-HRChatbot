{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Replace 'your_model_directory' with the path to your model's directory\n",
    "model_path = r\"C:\\Users\\spite\\Documents\\FT-Llama2-HR_Chatbot\\results\\final_merged_checkpoint\" \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "untrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Replace 'your_model_directory' with the path to your model's directory\n",
    "model_path = \"meta-llama/Llama-2-7b-hf\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_model(question, passage, max_length=200):\n",
    "    inputs = tokenizer.encode(question, return_tensors='pt')\n",
    "    outputs = model.generate(inputs, max_length=max_length, num_return_sequences=1)\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    response_start = response.find(\"### Response:\") + len(\"### Response:\")\n",
    "    response_end = response.find(\"### End\")\n",
    "    \n",
    "    # Clean up any leading or trailing whitespace or newline characters in the response\n",
    "    final_response = response[response_start:response_end].strip()\n",
    "    return final_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_model(question, passage, max_length=200):\n",
    "    \"\"\"\n",
    "    Generate a model response based on a question and a passage provided.\n",
    "    Format the output to extract the part between \"### Response:\" and \"### End\".\n",
    "    \n",
    "    :param question: The question to ask the model.\n",
    "    :param passage: The passage context for the model.\n",
    "    :param max_length: Maximum length of the generated response.\n",
    "    \"\"\"\n",
    "\n",
    "    RESPONSE_KEY = \"### Response:\"\n",
    "    END_KEY = \"### End\"\n",
    "    \n",
    "    # Encode the question and passage to the model's required input format\n",
    "    inputs = tokenizer.encode(question, return_tensors='pt')\n",
    "    outputs = model.generate(inputs, max_length=max_length, num_return_sequences=1)\n",
    "    \n",
    "    # Decode the generated response\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Extract the response part between the designated markers\n",
    "    response_start = response.find(RESPONSE_KEY) + len(RESPONSE_KEY)\n",
    "    response_end = response.find(END_KEY)\n",
    "    \n",
    "    # Clean up any leading or trailing whitespace or newline characters in the response\n",
    "    final_response = response[response_start:response_end].strip()\n",
    "    \n",
    "    return final_response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test 1\n",
    "passage = “Over the past three weeks, several users have been involved in multiple projects.User Noah has been involved in the following projects: Nature project where they worked week 1: 11 hours, week 2: 21 hours, and week 3: 20 hours. For the Harmony project, Noah worked 21 hours in week 1 and 12 hours in week 2. Noah did not work on the Harmony project in week 3. User Leah has contributed to the following projects: Fusion where she worked week 1: 15 hours, week 2: 18 hours, and week 3: 22 hours. In the Pulse project, Leah worked 10 hours in week 1 and 16 hours in week 2, but did not contribute any hours in week 3\n",
    "\n",
    "\n",
    "Question =  Can you calculate the total hours Noah worked on Nature project?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test 2\n",
    "passage = “Over the past three weeks, several users have been involved in multiple projects.User Noah has been involved in the following projects: Nature project where they worked week 1: 11 hours, week 2: 21 hours, and week 3: 20 hours. For the Harmony project, Noah worked 21 hours in week 1 and 12 hours in week 2. Noah did not work on the Harmony project in week 3. User Leah has contributed to the following projects: Fusion where she worked week 1: 15 hours, week 2: 18 hours, and week 3: 22 hours. In the Pulse project, Leah worked 10 hours in week 1 and 16 hours in week 2, but did not contribute any hours in week 3\n",
    "\n",
    "\n",
    "Question =  List the projects Leah contributed too please?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test 3\n",
    "passage = \"User Fiona has been involved in the following projects: Zenith where they worked week1: 12hrs, week2: 14hrs. Apex where they worked week1: 16hrs, week2: 22hrs.\",\n",
    "\n",
    "\n",
    "Question = Can you list all the projects Fiona was involved with please?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test 4\n",
    "passage = \"User Leah has contributed to the following projects: Fusion where she worked week 1: 15 hours, week 2: 18 hours, and week 3: 22 hours. In the Pulse project, Leah worked 10 hours in week 1 and 16 hours in week 2, but did not contribute any hours in week 3 \",\n",
    "\n",
    "\n",
    "Question =  \"Calculate the total hours Leah contributed to the Fusion project,please?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test 5\n",
    "passage = \"User Abigail has been involved in the following projects: Quest where they worked week1: 12hrs, week2: 13hrs.User Jayden has been involved in the following projects: Vertex where they worked week1: 18hrs, week2: 15hrs, week3: 19hrs.\",\n",
    "\n",
    "question =  \"in which projcts did Jayden contributed to please?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the passage and question\n",
    "passage = \"Over the past three weeks, several users have been involved in multiple projects.User Noah has been involved in the following projects: Nature project where they worked week 1: 11 hours, week 2: 21 hours, and week 3: 20 hours. For the Harmony project, Noah worked 21 hours in week 1 and 12 hours in week 2. Noah did not work on the Harmony project in week 3. User Leah has contributed to the following projects: Fusion where she worked week 1: 15 hours, week 2: 18 hours, and week 3: 22 hours. In the Pulse project, Leah worked 10 hours in week 1 and 16 hours in week 2, but did not contribute any hours in week 3\",\n",
    "\n",
    "question =  \"Can you calculate the total hours Noah worked on Nature project?\"\n",
    "\n",
    "# Call the updated ask_model function with both the question and passage\n",
    "response = ask_model(question,passage)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the passage and question\n",
    "passage = \"Over the past three weeks, several users have been involved in multiple projects.User Noah has been involved in the following projects: Nature project where they worked week 1: 11 hours, week 2: 21 hours, and week 3: 20 hours. For the Harmony project, Noah worked 21 hours in week 1 and 12 hours in week 2. Noah did not work on the Harmony project in week 3. User Leah has contributed to the following projects: Fusion where she worked week 1: 15 hours, week 2: 18 hours, and week 3: 22 hours. In the Pulse project, Leah worked 10 hours in week 1 and 16 hours in week 2, but did not contribute any hours in week 3\",\n",
    "\n",
    "question =  \"List the projects Leah contributed too please?\"\n",
    "\n",
    "# Call the updated ask_model function with both the question and passage\n",
    "response = ask_model(question,passage)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the passage and question\n",
    "passage =  \"User Fiona has been involved in the following projects: Zenith where they worked week1: 12hrs, week2: 14hrs. Apex where they worked week1: 16hrs, week2: 22hrs.\",\n",
    "\n",
    "question =  \"Can you list all the projects Fiona was involved with please?\"\n",
    "\n",
    "# Call the updated ask_model function with both the question and passage\n",
    "response = ask_model(question,passage)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the passage and question\n",
    "passage =  \"User Leah has contributed to the following projects: Fusion where she worked week 1: 15 hours, week 2: 18 hours, and week 3: 22 hours. In the Pulse project, Leah worked 10 hours in week 1 and 16 hours in week 2, but did not contribute any hours in week 3 \",\n",
    "\n",
    "\n",
    "question =  \"Calculate the total hours Leah contributed to the Fusion project,please?\"\n",
    "\n",
    "# Call the updated ask_model function with both the question and passage\n",
    "response = ask_model(question,passage)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the passage and question\n",
    "passage = \"User Abigail has been involved in the following projects: Quest where they worked week1: 12hrs, week2: 13hrs.User Jayden has been involved in the following projects: Vertex where they worked week1: 18hrs, week2: 15hrs, week3: 19hrs.\",\n",
    "\n",
    "question =  \"in which projcts did Jayden contributed to please?\"\n",
    "\n",
    "# Call the updated ask_model function with both the question and passage\n",
    "response = ask_model(question,passage)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(\"Welcome to the Chatbot Terminal! Please provide a question and a passage for analysis.\\n\")\n",
    "\n",
    "    # User input for the passage\n",
    "    passage = input(\"Enter your passage:\\n\")\n",
    "\n",
    "    # User input for the question\n",
    "    question = input(\"\\nEnter your question:\\n\")\n",
    "\n",
    "    # Processing the question and passage\n",
    "    print(\"\\nAnalyzing your question and calculating the response...\\n\")\n",
    "    response = ask_model(question, passage)\n",
    "    \n",
    "    # Displaying the response\n",
    "    print(\"Response:\\n\" + response)\n",
    "\n",
    "    print(\"\\nThank you for using the Chatbot Terminal! If you have another question, please start again.\")\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
